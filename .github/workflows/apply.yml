name: Terraform Apply Pipeline

concurrency:
  group: terraform-apply-${{ github.ref }}
  cancel-in-progress: true

on:
  workflow_dispatch:
  push:
    branches: [main]
  pull_request:

jobs:
  fmt-validate:
    uses: ./.github/workflows/fmt-validate.yml
    with:
      tf_version: ${{ vars.TF_VERSION }}

  plan:
    needs: fmt-validate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ vars.TF_VERSION }}

      - name: Terraform Init
        run: terraform init -input=false

      - name: Terraform Plan
        id: plan
        run: |
          terraform plan \
            -input=false \
            -out=tfplan

      - name: Upload Terraform Plan Artifact
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: tfplan

  apply:
    needs: plan
    if: github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    outputs:
      alb_role_arn: ${{ steps.tf_outputs.outputs.alb_role_arn }}
      cluster_name: ${{ steps.tf_outputs.outputs.cluster_name }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ vars.TF_VERSION }}

      - name: Download Terraform Plan Artifact
        uses: actions/download-artifact@v4
        with:
          name: tfplan

      - name: Terraform Init
        run: terraform init -input=false

      - name: Terraform Apply
        run: |
          terraform apply \
            -input=false \
            -auto-approve \
            tfplan

      - name: Export Terraform Outputs
        id: tf_outputs
        shell: bash
        run: |
          set -e
          ALB_ROLE_ARN="$(terraform output -raw alb_controller_role_arn | tr -d '\n' | tr -d '\r')"
          echo "alb_role_arn=${ALB_ROLE_ARN}" >> "$GITHUB_OUTPUT"

          CLUSTER_NAME="$(terraform output -raw cluster_name | tr -d '\n' | tr -d '\r')"
          echo "cluster_name=${CLUSTER_NAME}" >> "$GITHUB_OUTPUT"

  kubeconfig:
    needs: apply
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Debug cluster name
        run: |
          echo "Cluster name is: '${{ needs.apply.outputs.cluster_name }}'"

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.apply.outputs.cluster_name }} --region ${{ vars.AWS_REGION }}

      - name: Deploy AWS Load Balancer Controller Helm Chart
        env:
          NAMESPACE: fastfood
        run: |
          helm upgrade --install fastfood-k8s ./helm \
            --namespace $NAMESPACE \
            --create-namespace \
            --set namespace="$NAMESPACE" \
            --set alb.serviceAccount.roleArn=${{ needs.apply.outputs.alb_role_arn }} \

      - name: Install / Upgrade AWS Load Balancer Controller
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update

          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            --namespace kube-system \
            --create-namespace \
            --set clusterName=${{ needs.apply.outputs.cluster_name }} \
            --set region=${{ vars.AWS_REGION }} \
            --set vpcId=${{ vars.VPC_ID }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller

      - name: Get ALB DNS from Ingress
        id: alb_dns
        shell: bash
        run: |
          echo "Waiting for ALB DNS..."

          for i in {1..20}; do
            ALB_DNS=$(kubectl get ingress fastfood-ingress \
              -n fastfood \
              -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

            if [[ -n "$ALB_DNS" ]]; then
              echo "ALB DNS found: $ALB_DNS"
              echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT
              exit 0
            fi

            echo "ALB not ready yet... retrying ($i/20)"
            sleep 15
          done

          echo "ERROR: ALB DNS not available after timeout"
          exit 1

      - name: Save ALB DNS in SSM
        run: |
          aws ssm put-parameter \
            --name "/fastfood/alb/dns" \
            --value "${{ steps.alb_dns.outputs.alb_dns }}" \
            --type String \
            --overwrite
